{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import matplotlib as plt\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Learning Activities</th>\n",
       "      <th>Learning Technology</th>\n",
       "      <th>Course Structure</th>\n",
       "      <th>Communication</th>\n",
       "      <th>Learning Materials</th>\n",
       "      <th>Learning Objectives</th>\n",
       "      <th>Community</th>\n",
       "      <th>General</th>\n",
       "      <th>Instructor/TAs</th>\n",
       "      <th>Category_Title</th>\n",
       "      <th>Marked_Passage</th>\n",
       "      <th>text_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>COMMS 426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Learning Materials</td>\n",
       "      <td>It can be a little dense having to do both th...</td>\n",
       "      <td>It can be a little dense having to do both th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>IP&amp;T 371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Course Structure</td>\n",
       "      <td>All the information I needed to be successful ...</td>\n",
       "      <td>All the information I needed to be successful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>HLTH 335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Communication</td>\n",
       "      <td>I think some of the directions towards the end...</td>\n",
       "      <td>I think some of the directions towards the end...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>Psych 275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Course Structure</td>\n",
       "      <td>There has been a lot of confusion about when ...</td>\n",
       "      <td>There has been a lot of confusion about when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>NURS 491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Learning Materials</td>\n",
       "      <td>I have felt like there is more reading than i...</td>\n",
       "      <td>I have felt like there is more reading than i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>WRTG 150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Communication</td>\n",
       "      <td>I barely got any direction from my professor\\...</td>\n",
       "      <td>I barely got any direction from my professor\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>RELA 275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Learning Activities</td>\n",
       "      <td>Less writing</td>\n",
       "      <td>Less writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>PSYCH 358</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Course Structure</td>\n",
       "      <td>The lesson plans and routines are clearly defi...</td>\n",
       "      <td>The lesson plans and routines are clearly defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>PSYCH 338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Learning Materials</td>\n",
       "      <td>Being able to have a write up of the lectures ...</td>\n",
       "      <td>Being able to have a write up of the lectures ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>CHEM 101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>This course needs a total overhaul</td>\n",
       "      <td>This course needs a total overhaul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Course Sentiment  Learning Activities  Learning Technology  \\\n",
       "957   COMMS 426         0                    0                    0   \n",
       "2086   IP&T 371         0                    0                    0   \n",
       "3665   HLTH 335         0                    0                    0   \n",
       "1700  Psych 275         0                    0                    0   \n",
       "531    NURS 491         0                    0                    0   \n",
       "330    WRTG 150         0                    0                    0   \n",
       "4564   RELA 275         0                    1                    0   \n",
       "5766  PSYCH 358         1                    0                    0   \n",
       "2219  PSYCH 338         0                    0                    0   \n",
       "6517   CHEM 101         0                    0                    0   \n",
       "\n",
       "      Course Structure  Communication  Learning Materials  \\\n",
       "957                  1              0                   1   \n",
       "2086                 0              0                   1   \n",
       "3665                 0              1                   0   \n",
       "1700                 1              1                   0   \n",
       "531                  1              0                   1   \n",
       "330                  0              1                   0   \n",
       "4564                 0              0                   0   \n",
       "5766                 1              1                   0   \n",
       "2219                 0              0                   1   \n",
       "6517                 0              0                   0   \n",
       "\n",
       "      Learning Objectives  Community  General  Instructor/TAs  \\\n",
       "957                     0          0        0               0   \n",
       "2086                    0          0        0               0   \n",
       "3665                    0          0        0               0   \n",
       "1700                    0          0        0               0   \n",
       "531                     0          0        0               0   \n",
       "330                     0          0        0               1   \n",
       "4564                    0          0        0               0   \n",
       "5766                    0          0        0               0   \n",
       "2219                    0          0        0               0   \n",
       "6517                    0          0        1               0   \n",
       "\n",
       "           Category_Title                                     Marked_Passage  \\\n",
       "957    Learning Materials   It can be a little dense having to do both th...   \n",
       "2086     Course Structure  All the information I needed to be successful ...   \n",
       "3665        Communication  I think some of the directions towards the end...   \n",
       "1700     Course Structure   There has been a lot of confusion about when ...   \n",
       "531    Learning Materials   I have felt like there is more reading than i...   \n",
       "330         Communication   I barely got any direction from my professor\\...   \n",
       "4564  Learning Activities                                       Less writing   \n",
       "5766     Course Structure  The lesson plans and routines are clearly defi...   \n",
       "2219   Learning Materials  Being able to have a write up of the lectures ...   \n",
       "6517              General                 This course needs a total overhaul   \n",
       "\n",
       "                                              text_desc  \n",
       "957    It can be a little dense having to do both th...  \n",
       "2086  All the information I needed to be successful ...  \n",
       "3665  I think some of the directions towards the end...  \n",
       "1700   There has been a lot of confusion about when ...  \n",
       "531    I have felt like there is more reading than i...  \n",
       "330    I barely got any direction from my professor\\...  \n",
       "4564                                       Less writing  \n",
       "5766  The lesson plans and routines are clearly defi...  \n",
       "2219  Being able to have a write up of the lectures ...  \n",
       "6517                 This course needs a total overhaul  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read dataset\n",
    "with open('AllQualBaseThemes.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "df = pd.read_csv(\"AllQualBaseThemes.csv\", encoding=result['encoding'])\n",
    "df = df.dropna()\n",
    "df['Marked_Passage']=df['Marked_Passage'].apply(str)\n",
    "df['Category_Title']=df['Category_Title'].apply(str)\n",
    "df['text_desc'] = df['Marked_Passage']\n",
    "# Change the sentiment column into 1s and 0s. 1 for positive (P), 0 for negative (N)\n",
    "df.loc[df['Sentiment']=='P', 'Sentiment'] = 1\n",
    "df.loc[df['Sentiment'] == 'N', 'Sentiment'] = 0\n",
    "# Usually takes between 6-8 seconds to run this chunk\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df_x, type, to_pickle = True):\n",
    "    if type == 'tfidf':\n",
    "        transformer = TfidfVectorizer()\n",
    "        bag = transformer.fit_transform(df_x)\n",
    "        if to_pickle == True:\n",
    "            transformer_path = open(f'{directory}/tfidf_transformer.pkl', 'wb')\n",
    "            pickle.dump(transformer, transformer_path)\n",
    "            print('Tfidf bag of words successfully pickled into tfidf_transformer.pkl')\n",
    "    elif type == 'count_vect':\n",
    "        transformer = CountVectorizer()\n",
    "        bag = transformer.fit_transform(df_x)\n",
    "        if to_pickle == True:\n",
    "            transformer_path = open(f'{directory}/cv_transformer.pkl', 'wb')\n",
    "            pickle.dump(transformer, transformer_path)\n",
    "            print('Count vectorizer bag of words successfully pickled into cv_transformer.pkl')\n",
    "    X = bag.toarray()\n",
    "    return X\n",
    "\n",
    "def model_trainer2(label, x_column):\n",
    "    # label is the column name of df that corresponds to a category. Should be in string format.\n",
    "    # x_features must be in bag of words format, and is prepared in the extract_features function defined above\n",
    "    # df_y is the labeled data that is used to actually train the model. In this case, it is 1s and 0s in int form.\n",
    "    # It should not have been split yet.\n",
    "    df_y = df[label]\n",
    "    df_y = df_y.astype(int)\n",
    "    # Split data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_column, df_y, random_state = random_seed, test_size = 0.2)\n",
    "    # X_train is the transformed version of the comments that will be used to train the model. \n",
    "    # X_test is not used to train the model, but the model is applied to it for initial accuracy scores.\n",
    "    # y_train is the split version that is compared to the model\n",
    "    tfidf = TfidfVectorizer()\n",
    "    cv = CountVectorizer()\n",
    "    tfidf.fit_transform(X_train)\n",
    "    cv.fit_transform(X_train)\n",
    "\n",
    "    tf_bag = tfidf.transform(X_train)\n",
    "    cv_bag = cv.transform(X_train)\n",
    "    tf_test = tfidf.transform(X_test)\n",
    "    cv_test = cv.transform(X_test)\n",
    "    # (TO DO) Maybe tweak the hyperparameters of this model?\n",
    "    log_reg = LogisticRegression(C = 10, random_state = 27, solver = 'lbfgs', multi_class = 'ovr', max_iter=2000)\n",
    "    tf_model = log_reg.fit(tf_bag, y_train)\n",
    "    cv_model = log_reg.fit(cv_bag, y_train)\n",
    "\n",
    "    # Transform the testing data for accurate predictions\n",
    "    # Make predictions\n",
    "    tf_predict = log_reg.predict(tf_test)\n",
    "    cv_predict = log_reg.predict(cv_test)\n",
    "\n",
    "    tf_accuracy = metrics.accuracy_score(y_test, tf_predict)\n",
    "    cv_accuracy = metrics.accuracy_score(y_test, cv_predict)\n",
    "    print(f'Tfidf accuracy score for {label}: {round(tf_accuracy, 4)}')\n",
    "    print(f'Count Vectorizor accuracy score for {label}: {round(cv_accuracy, 4)}')\n",
    "\n",
    "    if tf_accuracy >= cv_accuracy:\n",
    "        model = tf_model\n",
    "        X_test = tf_test\n",
    "    else:\n",
    "        model = cv_model\n",
    "        X_test = cv_test\n",
    "\n",
    "    # y_predict = log_reg.predict(X_test)\n",
    "    # print(f'Comments that are being used for prediction: {X_test[:5]}')\n",
    "    # print(f'First 5 predictions: {y_predict[:5]}')\n",
    "    # tf_accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "    # print(f'{label} Accuracy Score: {round(metrics.accuracy_score(y_test, y_predict), 8)}')\n",
    "    # return the necessary elements that the pickle code will need to store the model\n",
    "    # also return the accuracy score to be compared against other extraction methods\n",
    "    return model, X_test\n",
    "\n",
    "\n",
    "def model_trainer(label, x_features):\n",
    "    # A simpler form of model_trainer2. Unlike model_trainer2, the xfeatures should have already been split and transformed.\n",
    "    # This prevents the same code from running multiple times when it doesn't need to be\n",
    "    df_y = TRAIN[label]\n",
    "    df_y = df_y.astype(int)\n",
    "    \n",
    "    logreg = LogisticRegression(C = 10, random_state = 11, solver = 'lbfgs', multi_class = 'ovr', max_iter = 2000)\n",
    "    model = logreg.fit(x_features, df_y)\n",
    "    # TODO Test whether the initial accuracy metric being included here screws things up.\n",
    "    # TODO Maybe make a separate function that finds accuracy??\n",
    "\n",
    "    return model\n",
    "\n",
    "def check_accuracy(model, transformer, category):\n",
    "    y_test = TEST['text_desc']\n",
    "    y_preds = model.predict()\n",
    "    score = metrics.accuracy_score(y_test, y_preds)\n",
    "    print(f'Accuracy score for {category}: {round(score, 4)}')\n",
    "    # TODO finish this function\n",
    "\n",
    "def get_top_k_predictions(model, X_test,k):\n",
    "    # get probabilities instead of predicted labels, since we want to collect top k\n",
    "    np.set_printoptions(suppress=True)\n",
    "    probs = model.predict_proba(X_test)\n",
    "\n",
    "    # GET TOP K PREDICTIONS BY PROB - note these are just index\n",
    "    best_n = np.argsort(probs, axis=1)[:,-k:]\n",
    "    \n",
    "    # GET CATEGORY OF PREDICTIONS\n",
    "    preds = [\n",
    "    [(model.classes_[predicted_cat], distribution[predicted_cat])\n",
    "     for predicted_cat in prediction]\n",
    "    for distribution, prediction in zip(probs, best_n)]\n",
    "    \n",
    "    preds=[ item[::-1] for item in preds]\n",
    "    return preds\n",
    "\n",
    "def pickler(model, category):\n",
    "    # model_path = open(f'{category} model.pkl', 'wb')\n",
    "    model_path = open(f'{directory}/{category} model.pkl', 'wb')\n",
    "    # we need to save both the transformer -> to encode a document and the model itself to make predictions based on the weight vectors \n",
    "    pickle.dump(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df: 6812\n",
      "Learning Activities: 1846 (27.1%)\n",
      "Learning Technology: 307 (4.51%)\n",
      "Course Structure: 1966 (28.86%)\n",
      "Communication: 893 (13.11%)\n",
      "Learning Materials: 1639 (24.06%)\n",
      "Learning Objectives: 557 (8.18%)\n",
      "Community: 393 (5.77%)\n",
      "General: 306 (4.49%)\n",
      "Instructor/TAs: 569 (8.35%)\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all categories, with a model to be run surrounding each item\n",
    "categories = ['Learning Activities', 'Learning Technology', 'Course Structure', 'Communication',\n",
    " 'Learning Materials', 'Learning Objectives', 'Community', 'General', 'Instructor/TAs']\n",
    "\n",
    "# A chance to change up the randomness of the testing and training data\n",
    "random_seed = 16\n",
    "\n",
    "# Make a new directory for the pickle files\n",
    "directory = os.path.join(os.getcwd(), '.pklfiles')\n",
    "# Clear out and delete the folder of .pklfiles if it exists\n",
    "if os.path.exists(directory):\n",
    "    shutil.rmtree(directory)\n",
    "os.mkdir(directory)\n",
    "\n",
    "# EDA and plotting (TODO finish this later?)\n",
    "ones = {}\n",
    "print(f'Number of rows in df: {df.shape[0]}')\n",
    "for item in categories:\n",
    "    counter = 0\n",
    "    for i in df[item]:\n",
    "        if i == 1:\n",
    "            counter += 1\n",
    "    proportion = (counter / df.shape[0]) * 100\n",
    "    print(f'{item}: {counter} ({round(proportion, 2)}%)')   \n",
    "    ones[item] = counter\n",
    "\n",
    "# keys = list(ones.keys())\n",
    "# vals = list(ones.values())\n",
    "\n",
    "# plt.bar(range(len(ones)), vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 14)\n",
      "(5449, 3604)\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that will be incrementally added to and that will become the excel spreadsheet\n",
    "results = {\n",
    "    'Text': [],\n",
    "    'Sentiment': [],\n",
    "    'Learning Activities': [],\n",
    "    'Learning Technology': [], \n",
    "    'Course Structure': [],\n",
    "    'Communication': [],\n",
    "    'Learning Materials': [],\n",
    "    'Learning Objectives': [],\n",
    "    'Community': [],\n",
    "    'General': [],\n",
    "    'Instructor/TAs': [],\n",
    "    'Sentiment Reality': [],\n",
    "    'Activities Reality': [],\n",
    "    'Technology Reality': [],\n",
    "    'Structure Reality': [],\n",
    "    'Communication Reality': [],\n",
    "    'Materials Reality': [],\n",
    "    'Objectives Reality': [],\n",
    "    'Community Reality': [],\n",
    "    'General Reality': [],\n",
    "    'Instructors Reality': []\n",
    "}\n",
    "# These will be the column names in the output spreadsheet that will be generated at the end of the program\n",
    "data_columns = ['Text', 'Sentiment', 'Learning Activities', 'Learning Technology', 'Course Structure', \n",
    "'Communication', 'Learning Materials', 'Learning Objectives', 'Community','General', \n",
    "'Instructor/TAs', 'Sentiment Reality', 'Activities Reality', 'Technology Reality', 'Structure Reality', \n",
    "'Communication Reality', 'Materials Reality', 'Objectives Reality', 'Community Reality',\n",
    "'General Reality', 'Instructors Reality']\n",
    "\n",
    "# Split the data into training and testing data frames (All y columns included)\n",
    "TRAIN, TEST = train_test_split(df, test_size = 0.2, random_state = random_seed)\n",
    "print(TRAIN.shape)\n",
    "\n",
    "# Fill out half of the output spreadsheet with the actual reference values. The rest will be filled with predictions on the same comments. Will be good for comparison.\n",
    "for i in range(len(TEST)):\n",
    "    results['Text'].append(TEST.text_desc.iloc[i])\n",
    "    results['Activities Reality'].append(TEST['Learning Activities'].iloc[i])\n",
    "    results['Technology Reality'].append(TEST['Learning Technology'].iloc[i])\n",
    "    results['Structure Reality'].append(TEST['Course Structure'].iloc[i])\n",
    "    results['Communication Reality'].append(TEST['Communication'].iloc[i])\n",
    "    results['Materials Reality'].append(TEST['Learning Materials'].iloc[i])\n",
    "    results['Objectives Reality'].append(TEST['Learning Objectives'].iloc[i])\n",
    "    results['Community Reality'].append(TEST.Community.iloc[i])\n",
    "    results['General Reality'].append(TEST.General.iloc[i])\n",
    "    results['Sentiment Reality'].append(TEST.Sentiment.iloc[i])\n",
    "    results['Instructors Reality'].append(TEST['Instructor/TAs'].iloc[i])\n",
    "\n",
    "# Create a bag of words in two different ways and create a pickle file for each method\n",
    "\n",
    "# tfidf = extract_features(df_x = df['text_desc'], type = 'tfidf', to_pickle = True)\n",
    "# count_vect = extract_features(df_x = df['text_desc'], type = 'count_vect', to_pickle = True)\n",
    "pickle_directory = os.path.join(os.getcwd(), '.pklfiles')\n",
    "tfidf = TfidfVectorizer()\n",
    "cv = CountVectorizer()\n",
    "tfidf_trainX = tfidf.fit_transform(TRAIN['text_desc'])\n",
    "cv_trainX = cv.fit_transform(TRAIN['text_desc'])\n",
    "print(cv_trainX.shape)\n",
    "pickle.dump(tfidf, open(f'{pickle_directory}/tfidf_transformer.pkl', 'wb'))\n",
    "pickle.dump(cv, open(f'{pickle_directory}/cv_transformer.pkl', 'wb'))\n",
    "\n",
    "# tf_bag = tfidf.transform(X_train)\n",
    "# cv_bag = cv.transform(X_train)\n",
    "tf_test = tfidf.transform(TEST['text_desc'])\n",
    "cv_test = cv.transform(TEST['text_desc'])\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(C = 10, random_state = 11, solver = 'lbfgs', multi_class = 'ovr', max_iter = 2000)\n",
    "model = logreg.fit(X = tfidf_trainX, y = TRAIN['Learning Activities'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through all the results for Sentiment to highlight the process\n",
    "\n",
    "# First, extract features from the comments by making a bag of words. There are two main ways to do this, so we will prepare this for both. \n",
    "# Note that later on, you won't actually have to repeat the process for every new category / model. These functions will be called again below because this cell is optional.\n",
    "# x_tfidf = extract_features(df_x = df.Marked_Passage, type = 'tfidf', to_pickle = False)\n",
    "# x_cv = extract_features(df_x = df.Marked_Passage, type = 'count_vect', to_pickle = False)\n",
    "\n",
    "'''Once the features have been extracted, it is time to actually train the model\n",
    "The model_trainer function creates a logistic regression between the 0s and 1s in your category column (label) and the array of words that you just extracted (x_features)\n",
    "model_trainer also makes predictions with the newly created model and calculates an overall accuracy score by comparing predictions with testing data\n",
    "We run model_trainer twice with each category to see which feature extraction works better. model_trainer will print the accuracy score at the end and the code will compare them.'''\n",
    "\n",
    "# PvN_model_tf, accuracy_tf, PvN_X_test = model_trainer(label = 'Sentiment', x_features = x_tfidf)\n",
    "# PvN_Model_cv, accuracy_cv, PvN_X_test_cv = model_trainer(label = 'Sentiment', x_features = x_cv)\n",
    "sentiment_model, sentiment_x = model_trainer(label = 'Sentiment', x_column = df['text_desc'])\n",
    "\n",
    "# Compare the two accuracy scores. They are usually close, but they vary in terms of which one actually performs better\n",
    "# if accuracy_tf >= accuracy_cv:\n",
    "#     print('For sentiment analysis, the Tfidf vectorizer produced more accurate results.')\n",
    "#     # This creates a pickle file, which stores a python object (the model itself) in a file that can be accessed in other scripts andfiles.\n",
    "#     pickler(model = PvN_model_tf, category = 'Sentiment Analysis')\n",
    "#     # Make probability predictions as well\n",
    "#     predictions = get_top_k_predictions(PvN_model_tf, X_test = PvN_X_test, k = 2)\n",
    "# else:\n",
    "#     print('For Sentiment Analysis, the Count Vectorizer produced more accurate results.')\n",
    "#     pickler(model = PvN_Model_cv, category = 'Sentiment Analysis')\n",
    "#     predictions = get_top_k_predictions(PvN_Model_cv, X_test = PvN_X_test_cv, k = 2)\n",
    "sentiment_pickle_path = f'{directory}/Sentiment model.pkl'\n",
    "pickle.dump(sentiment_model, open(sentiment_pickle_path, 'wb'))\n",
    "\n",
    "predictions = get_top_k_predictions(model = sentiment_model, X_test = sentiment_x, k = 2)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i][0][0] == 1:\n",
    "        results['Sentiment'].append(format(predictions[i][0][1], '.5f'))\n",
    "    else:\n",
    "        results['Sentiment'].append(format(predictions[i][1][1], '.5f'))\n",
    "# Show a few predictions and see how confident they are\n",
    "for i in range(10):\n",
    "    print(x_test.iloc[i])\n",
    "    print(predictions[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449,)\n",
      "(5449,)\n",
      "(5449,)\n",
      "(5449,)\n",
      "(5449,)\n",
      "(5449,)\n",
      "(5449,)\n",
      "(5449,)\n",
      "(5449,)\n"
     ]
    }
   ],
   "source": [
    "for item in categories:\n",
    "    # model, test = model_trainer(label = item, x_column = df['text_desc'])\n",
    "    model = model_trainer(label = item, x_features = cv_trainX)\n",
    "    if item == 'Instructor/TAs':\n",
    "        category = 'Instructors'\n",
    "    else:\n",
    "        category = item\n",
    "    pickle_path = f'{directory}/{category} model.pkl'\n",
    "    pickle.dump(model, open(pickle_path, 'wb'))\n",
    "    preds = get_top_k_predictions(model = model, X_test = cv_test, k = 2)\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i][0][0] == 1:\n",
    "            results[item].append(format(preds[i][0][1], '.5f'))\n",
    "        else:\n",
    "            results[item].append(format(preds[i][1][1], '.5f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home = os.getcwd()\n",
    "# sentiment_path = os.path.join(home, '.pklfiles/Sentiment Analysis model.pkl')\n",
    "# loaded_model = pickle.load(open(sentiment_path, 'rb'))\n",
    "# loaded_preds = get_top_k_predictions(model = loaded_model, X_test = sentiment_x, k = 2)\n",
    "# for i in range(10):\n",
    "#     print(x_test_text.iloc[i])\n",
    "#     print(loaded_preds[i])\n",
    "for val in results.keys():\n",
    "    print(val + '\\t' + str(len(results[val])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all the information and make a database that can be exported as an excel sheet\n",
    "Data = pd.DataFrame(results, columns = data_columns)\n",
    "Data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to an excel file\n",
    "file_name = 'ML sample output.csv'\n",
    "Data.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.getcwd()\n",
    "model_filepath = f'.pklfiles/Sentiment model.pkl'\n",
    "category_model_file = os.path.join(home, model_filepath)\n",
    "category_loaded_model = pickle.load(open(category_model_file, 'rb'))\n",
    "extraction_path = os.path.join(home, '.pklfiles/cv_transformer.pkl')\n",
    "comment = ['I feel like there is a lot of busywork sometimes']\n",
    "transformed_comment = cv.transform(comment)\n",
    "pred = get_top_k_predictions(category_loaded_model, transformed_comment, 2) # This line works, showing that the non-pickled transformer works with a pickled model\n",
    "print(pred) \n",
    "category_loaded_transformer = pickle.load(open(extraction_path, 'rb'))\n",
    "category_test_features = category_loaded_transformer.transform(comment)\n",
    "prediction = get_top_k_predictions(category_loaded_model, category_test_features, 2)\n",
    "# This doesn't work, showing that the pickled transformer does not work here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9b66c5a3f4d504968e7c23ed073d920cce91d6e0d9896db397b1ddec9f4c1bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
